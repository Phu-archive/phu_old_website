<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>Phu's Website: Deep Reinforcement Learning Lecture 8</title>

<meta property="description" itemprop="description" content="Learning Dynamical Systems From Data"/>

<link rel="canonical" href="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2019-02-12"/>
<meta property="article:created" itemprop="dateCreated" content="2019-02-12"/>
<meta name="article:author" content="Phu Sakulwongtana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Phu&#39;s Website: Deep Reinforcement Learning Lecture 8"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Learning Dynamical Systems From Data"/>
<meta property="og:url" content="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"/>
<meta property="og:image" content="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/Images/Figure1.png"/>
<meta property="og:image:width" content="1696"/>
<meta property="og:image:height" content="744"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Phu&#39;s Website"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Phu&#39;s Website: Deep Reinforcement Learning Lecture 8"/>
<meta property="twitter:description" content="Learning Dynamical Systems From Data"/>
<meta property="twitter:url" content="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"/>
<meta property="twitter:image" content="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/Images/Figure1.png"/>
<meta property="twitter:image:width" content="1696"/>
<meta property="twitter:image:height" content="744"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Phu&#39;s Website: Deep Reinforcement Learning Lecture 8"/>
<meta name="citation_fulltext_html_url" content="http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"/>
<meta name="citation_online_date" content="2019/02/12"/>
<meta name="citation_publication_date" content="2019/02/12"/>
<meta name="citation_author" content="Phu Sakulwongtana"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Learning to control a low-cost manipulator using data-efficient reinforcement learning;citation_publication_date=2012;citation_publisher=MITP;citation_author=Hugh Durrant-Whyte;citation_author=Nicholas Roy;citation_author=Pieter Abbeel"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","bibliography","output","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Deep Reinforcement Learning Lecture 8"]},{"type":"character","attributes":{},"value":["Learning Dynamical Systems From Data"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Phu Sakulwongtana"]},{"type":"character","attributes":{},"value":["https://phutoast.github.io/"]}]}]},{"type":"character","attributes":{},"value":["02-12-2019"]},{"type":"character","attributes":{},"value":["biblio.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","toc_depth"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[2]}]}]},{"type":"character","attributes":{},"value":["http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"]},{"type":"character","attributes":{},"value":["http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["biblio.bib","deep-rl-lecture-8_files/bowser-1.9.3/bowser.min.js","deep-rl-lecture-8_files/distill-2.2.21/template.v2.js","deep-rl-lecture-8_files/jquery-1.11.3/jquery.min.js","deep-rl-lecture-8_files/webcomponents-2.0.0/webcomponents.js","Images/Figure1.png","Images/Figure2.png","Images/Figure3.png","Images/Figure4.png","Images/Figure5.png","Images/Figure6.png","katex.html","katex.min.css","katex.min.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.radix-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.radix-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.radix-site-nav a {
  color: inherit;
  text-decoration: none;
}

.radix-site-nav a:hover {
  color: white;
}

@media print {
  .radix-site-nav {
    display: none;
  }
}

.radix-site-header {

}

.radix-site-footer {

}


/* Site Header */

.radix-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.radix-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .radix-site-header .nav-left {
    margin-left: 0;
  }
}


.radix-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.radix-site-header a,
.radix-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.radix-site-header .title {
  font-size: 18px;
}

.radix-site-header .logo {
  padding: 0;
}

.radix-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.radix-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .radix-site-header .logo img {
    display: inline-block;
  }
  .radix-site-header .nav-left {
    margin-left: 20px;
  }
  .radix-site-header .nav-right {
    margin-right: 20px;
  }
  .radix-site-header .title {
    padding-left: 12px;
  }
}


.radix-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .radix-site-header a, .radix-site-header .nav-dropdown  {display: none;}
  .radix-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .radix-site-header .title {
    margin-left: 0;
  }
  .radix-site-header .nav-right {
    margin-right: 0;
  }
  .radix-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .radix-site-header.responsive {position: relative;}
  .radix-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .radix-site-header.responsive a,
  .radix-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .radix-site-header.responsive .nav-left,
  .radix-site-header.responsive .nav-right {
    width: 100%;
  }
  .radix-site-header.responsive .nav-dropdown {float: none;}
  .radix-site-header.responsive .nav-dropdown-content {position: relative;}
  .radix-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.radix-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet"/>
<script src="../../site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="../../site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.radix-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110171854-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-110171854-1');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Deep Reinforcement Learning Lecture 8","description":"Learning Dynamical Systems From Data","authors":[{"author":"Phu Sakulwongtana","authorURL":"https://phutoast.github.io/","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-02-12T00:00:00.000+00:00","citationText":"Sakulwongtana, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="radix-site-nav radix-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">Phu's Website</a>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="../../notes.html">Notes</a>
<a href="../../blog.html">Blogs</a>
<a href="../../CV.pdf">CV</a>
<a href="https://github.com/phutoast">
<i class="fab fa-github"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Deep Reinforcement Learning Lecture 8</h1>
<p>Learning Dynamical Systems From Data</p>
</div>

<div class="d-byline">
  Phu Sakulwongtana <a href="https://phutoast.github.io/" class="uri">https://phutoast.github.io/</a> 
  
<br/>02-12-2019
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#learning-models">Learning Models</a></li>
<li><a href="#case-study---model-based-policy-search-with-gaussian-process6301026">Case Study - Model Based Policy Search with Gaussian Process<span class="citation" data-cites="6301026">(Durrant-Whyte, Roy, and Abbeel <span>2012</span>)</span></a></li>
<li><a href="#local-models">Local Models</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="learning-models">Learning Models</h2>
<p>If we know the dynamic</p>
<p><span class="math display">\[
f(s_t, a_t) = s_{t+1}
\]</span></p>
<p>we could use the tool from last time to plan the new action.</p>
<h3 id="model-based-reinforcement-learning-version-0.5">Model Based Reinforcement Learning version 0.5</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="Images/Figure1.png" alt="Version 0.5" width="848" />
<p class="caption">
Figure 1: Version 0.5
</p>
</div>
</div>
<p><strong>Does it work ? (Yes)</strong></p>
<ul>
<li><p>It is how system identification works in classical robotics.</p></li>
<li><p>Some care should be takedn to design a good base policy</p></li>
<li><p>Effective if we can hand-engineer a dynamic representation using our knowledge of physics and fit just parameters.</p></li>
</ul>
<p><strong>Does it work? (No)</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="Images/Figure2.png" alt="Distribution Mismatch (Inspired from In-Slide Figure)" width="1044" />
<p class="caption">
Figure 2: Distribution Mismatch (Inspired from In-Slide Figure)
</p>
</div>
</div>
<p>Given this scenario, if we want to have an agent that reaches the peak. we can collect some data.</p>
<p>However the model going to assume that as you go more to the right, you elevation will be higher, which isn’t 100% correct since it will make the robot jump off the cliff at some point.</p>
<p>The problem is that we collect the data from difference distribution. We first collect from</p>
<p><span class="math display">\[
\pi_0(a_t|s_t)
\]</span> but we see</p>
<p><span class="math display">\[
p_{\pi_f}(x_t)
\]</span></p>
<p>The distribution mismatch problem becomes exacerbated as we use more expressive model classes.</p>
<h3 id="model-based-reinforcement-learning-version-1.0-and-1.5">Model Based Reinforcement Learning version 1.0 and 1.5</h3>
<p>Can we make</p>
<p><span class="math display">\[
p_{\pi_f}(s_t) = p_{\pi_0}(s_t)
\]</span></p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="Images/Figure3.png" alt="Version 1.0" width="862" />
<p class="caption">
Figure 3: Version 1.0
</p>
</div>
</div>
<p><strong>What if we make a mistake?</strong></p>
<p>The error can build up. We might fix this by once the mistake is getting big, replan and fix the error.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="Images/Figure4.png" alt="Version 1.5" width="884" />
<p class="caption">
Figure 4: Version 1.5
</p>
</div>
</div>
<h3 id="how-do-we-replan">How do we replan ?</h3>
<ul>
<li><p>The more you replan the less perfect each individual plan need to be.</p></li>
<li><p>Can use short horizon.</p></li>
<li><p>Even random sampling can often work.</p></li>
</ul>
<p>There seem to be a lot of works, can’t we just bake the learned policy. Back-propagation through the policy ?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="Images/Figure5.png" alt="Version 2.0" width="838" />
<p class="caption">
Figure 5: Version 2.0
</p>
</div>
</div>
<h3 id="summary">Summary</h3>
<ul>
<li><p>Version 0.5 – Collect random sample, Train dynamics plan</p>
<ul>
<li>Pro – Simple, No Iterative Procedure</li>
<li>Con – Distribution mismatch problem.</li>
</ul></li>
<li><p>Version 1.0 – Iteratively Collect Data, Replan and Collect Data</p>
<ul>
<li>Pro – Simple, solve distribution mismatch</li>
<li>Con – Open loop plan might perform poorly especially in stochastic domains</li>
</ul></li>
<li><p>Version 1.5 – Iteratively Collect Data using MPC (plan every step)</p>
<ul>
<li>Pro – Robust to small model Error</li>
<li>Con – Computationally Expensive but have planning algorithm avaliable.</li>
</ul></li>
<li><p>Version 2.0 – Backpropagation directly into policy</p>
<ul>
<li>Pro – Cheap at Run-Time</li>
<li>Con – Numerically Unstable, especially in stochastic environment.</li>
</ul></li>
</ul>
<hr />
<h2 id="case-study---model-based-policy-search-with-gaussian-process6301026">Case Study - Model Based Policy Search with Gaussian Process<span class="citation" data-cites="6301026">(Durrant-Whyte, Roy, and Abbeel <a href="#ref-6301026">2012</a>)</span></h2>
<p>The overview of the algorithm is</p>
<p>The hard part should be at the third step, where given <span class="math inline">\(p(s_t)\)</span>. We use <span class="math inline">\(p(s&#39;|s, a)\)</span>. To compute</p>
<p><span class="math display">\[
p(s_{t+1})
\]</span></p>
<p>If the current policy is Gaussian, we can get <span class="math inline">\(\bar{p}(s_{t+1})\)</span> in closed form. We can project the probability into a Gaussian using moment matching, the we calculate</p>
<p><span class="math display">\[
\mathbb{E}_{s \sim p(s)} [c(s)]
\]</span></p>
<p>is easy to compute of <span class="math inline">\(c\)</span> is nice, and <span class="math inline">\(p(s)\)</span> is gaussian. Then we write</p>
<p><span class="math display">\[
\sum_t \mathbb{E}_{s \sim p(s)}[r(s)]
\]</span></p>
<p>and differentiate.</p>
<h3 id="what-kind-of-model-should-we-use">What kind of model should we use ?</h3>
<ul>
<li><p>Gaussian Process [Input – <span class="math inline">\((s, a)\)</span> and Output – <span class="math inline">\(s&#39;\)</span>]</p>
<ul>
<li>Pro – Very Data Efficient</li>
<li>Con – Not Great With Non-Smooth Dynamics</li>
<li>Con – Very Slow when data is big</li>
</ul></li>
<li><p>Neural Network</p>
<ul>
<li><p>Euclidean Training Loss correspond to Gaussian <span class="math inline">\(p(s&#39;|s, a)\)</span></p></li>
<li><p>More Complex Loss, for example, output parameter of Gaussian Mixture</p></li>
<li><p>Pro – Very Expressive, when we can use a lot of data</p></li>
<li><p>Con – Not So Great in Low Data Regimes.</p></li>
</ul></li>
<li><p>Others</p>
<ul>
<li><p>Gaussian Mixture Model over <span class="math inline">\((s, a, s&#39;)\)</span> – Train on <span class="math inline">\((s, a, s&#39;)\)</span> condition to get, for i-th mixture element gives region where the mode holds <span class="math inline">\(p(s&#39;|s, a)\)</span></p></li>
<li><p>Other Classes – Domain Specific Models</p></li>
</ul></li>
</ul>
<hr />
<h2 id="local-models">Local Models</h2>
<h3 id="problem-with-global-models">Problem with Global Models</h3>
<p>Global Model represent by, mostly, Neural Network. Planner will seek out regions where model is erroneously optimistics.</p>
<p>Need to find good model in most of the state space to converge on a good policy. In some task the model is much more complext that policy (for example robot holding a glass).</p>
<h3 id="local-model">Local Model</h3>
<p>Learning local model to get the derivatives of</p>
<p><span class="math display">\[
\frac{df}{dx_t}, \frac{df}{du_t}
\]</span></p>
<p>Idea – Just fit derivatives around current trajectory or policy.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="Images/Figure6.png" alt="Process of Training Controller(Inspired from In-Slide Figure)" width="578" />
<p class="caption">
Figure 6: Process of Training Controller(Inspired from In-Slide Figure)
</p>
</div>
</div>
<p>The model can be</p>
<p><span class="math display">\[
\begin{aligned}
p(x_{t+1} | x_t, u_t) &amp;= \mathcal{N}(f(x_t, u_t), \Sigma) \\
f(x_t, u_t) &amp;\approx A_tx_t + B_tu_t \text{ where } A_t = \frac{df}{dx_t} \quad B_t = \frac{df}{du_t}
\end{aligned}
\]</span></p>
<p><strong>Which Controller we should execute ?</strong></p>
<p>The iLQR gives</p>
<p><span class="math display">\[
\hat{x}_t, \hat{u}_t, K_t, k
\]</span></p>
<p>where</p>
<p><span class="math display">\[
u_t = K_t(x_t - \hat{x}_t) + k_t + \hat{u}_t
\]</span></p>
<p>There are 3 different versions we can consider.</p>
<ul>
<li>Version 0.5 – This doesn’t correct drift</li>
</ul>
<p><span class="math display">\[
p(u_t|x_t) = \delta(u_t = \hat{u}_t)
\]</span></p>
<ul>
<li>Version 1.0</li>
</ul>
<p><span class="math display">\[
p(u_t|x_t) = \delta(u_t = K_t(x_t - \hat{x}_t) + k_t + \hat{u}_t)
\]</span></p>
<ul>
<li>Version 1.5 – Adding Noise to it</li>
</ul>
<p><span class="math display">\[
p(u_t|x_t) = \mathcal{N}( K_t(x_t - \hat{x}_t) + k_t + \hat{u}_t, \Sigma_t)
\]</span></p>
<p>We can set the variance of the probability to be</p>
<p><span class="math display">\[
\Sigma_t = Q^{-1}_{u_t, u_t}
\]</span></p>
<p>It is a cost to go or total cost.</p>
<p><span class="math display">\[
Q(x_t, u_t) = \text{const} + \frac{1}{2} \begin{bmatrix} x_t \\ u_t  \end{bmatrix}^T Q_t \begin{bmatrix} x_t \\ u_t  \end{bmatrix} + \begin{bmatrix} x_t \\ u_t  \end{bmatrix}^T q_t
\]</span></p>
<p>If the value is big, then we want to be careful with the action. We can show that while the standard LQR solves</p>
<p><span class="math display">\[
\min \sum^T_{t=1} c(x_t, u_t)
\]</span></p>
<p>This linear Gaussian solution with <span class="math inline">\(\Sigma_t = Q^{-1}_{u_t, u_t}\)</span> solves</p>
<p><span class="math display">\[
\min \sum^T_{t=1} \mathbb{E}_{(x, t) \sim p(x_t, u_t)} \left[ c(x_t, u_t) - \mathcal{H}(p(u_t|x_t)) \right]
\]</span></p>
<p>Act randomly as possible while minimizing costs.</p>
<h3 id="how-to-fit-dynamics">How to fit dynamics?</h3>
<p>Given the dataset</p>
<p><span class="math display">\[
\{(x_t, u_t, x_{t+1})\}
\]</span></p>
<p><strong>Version 1.0</strong></p>
<p>We can fit the transition probability at each time-step using linear regression</p>
<p><span class="math display">\[
p(x_{t+1}|x_t, u_t) = \mathcal{N}(A_tx_t + B_tu_t + c; N_t)
\]</span></p>
<p><strong>Version 2.0</strong></p>
<p>We can fit the probability using Baysian Linear Regression, by using global model as prior.</p>
<h3 id="what-if-we-goes-too-far">What if we goes too far ?</h3>
<p>Local model means that it works in local region, if we change the controller too much, then it is not local anymore. So, we will have to stay close to the old controller.</p>
<p><span class="math display">\[
p(u_t|x_t ) = \mathcal{N} (K_t(x_t - \hat{x}_t) + k_t + \hat{u_t}, \Sigma_t)
\]</span></p>
<p>Where the trajectory distribution is</p>
<p><span class="math display">\[
p(\tau) = p(x_1) \prod^T_{t=1} p(u_t|x_t) p(x_{t+1}|u_t, x_t) 
\]</span></p>
<p>What if the trajectory distribution is close to old one ? If the trajectory distribution is closed, then dynamics will be close to.</p>
<p><span class="math display">\[
D_{KL}(p(\tau) || \tilde{p}(\tau)) \le \epsilon
\]</span></p>
<p>We first expand the equations.</p>
<p><span class="math display">\[
D_{KL}(p(\tau) || \tilde{p}(\tau)) = \mathbb{E}_{p(\tau)} [\log p(\tau) - \log \tilde{p}(\tau)]
\]</span></p>
<p>The difference between the trajectories is only the policy.</p>
<p><span class="math display">\[
\begin{aligned}
p(\tau) &amp;= p(x_1) \prod^T_{t=1} p(u_t|x_t) p(x_{t+1}|u_t, x_t)  \\
\tilde{p}(\tau) &amp;= p(x_1) \prod^T_{t=1} \tilde{p}(u_t|x_t) p(x_{t+1}|u_t, x_t) 
\end{aligned}
\]</span></p>
<p>Expand the difference between the log probabilities</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\log p(\tau) - \log \tilde{p}(\tau) \\
&amp;= \log p(x_t) + \sum^T_{t=1} \log p(u_t|x_t) + \log p(x_{t+1}|x_t, u_t) \\ 
&amp;- \cancel{\log p(x_t)} - \sum^T_{t=1} \log \tilde{p}(u_t|x_t) - \cancel{\log p(x_{t+1}|x_t, u_t)}
\end{aligned}
\]</span></p>
<p>The KL-Divergence becomes</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}_{p(\tau)} \left[ \sum^T_{t=1} \log p(u_t|x_t)  - \log \tilde{p}(u_t|x_t)  \right] &amp;= \sum^T_{t=1} \mathbb{E}_{p(x_t, u_t)} \left[ \log p(u_t|x_t) - \log \tilde{p}(u_t|x_t) \right] \\
&amp;= \sum^T_{t=1}\mathbb{E}_{p(x_t, u_t)} \left[ \log\tilde{p} (u_t|x_t) \right] + \underbrace{\mathbb{E}_{p(x_t)}\left[ \mathbb{E}_{p(u_t|x_t)} [\log p(u_t|x_t)] \right]}_{\text{Negative Entropy}}
\end{aligned}
\]</span></p>
<p>They are similar as what linear gaussian we are trying to solve. (instead of the const we maximize the probability)</p>
<p><span class="math display">\[
\min \sum^T_{t=1} \mathbb{E}_{(x, t) \sim p(x_t, u_t)} \left[ -\log \tilde{p}(x_t, u_t) - \mathcal{H}(p(u_t|x_t)) \right]
\]</span></p>
<p>If we can get the KL into loss, we can just use iLQR. How can we constrain the KL-divergence loss ?</p>
<h3 id="dual-gradient-descent.">Dual Gradient Descent.</h3>
<p>Given the optimization problem</p>
<p><span class="math display">\[
\min_x f(x) \text{ such that } C(x) = 0
\]</span></p>
<p>We can then frames the loss to be</p>
<p><span class="math display">\[
\mathcal{L}(x, \lambda) = f(x) + \lambda C(x)
\]</span></p>
<p>where</p>
<p><span class="math display">\[
g(\lambda) = \inf_{x} \mathcal{L} (x, \lambda)  \quad \lambda \leftarrow \arg\max_{\lambda} g(\lambda)
\]</span></p>
<p>We can maximize, by computing the gradient</p>
<p><span class="math display">\[
g(\lambda) = \mathcal{L}(x^*(\lambda), \lambda) \quad \frac{dg}{d\lambda} = \frac{d\mathcal{L}}{dx^*}\frac{dx^*}{d\lambda} + \frac{d\mathcal{L}}{d\lambda}
\]</span></p>
<p>If</p>
<p><span class="math display">\[
x^* = \arg\min_x \mathcal{L}(x, \lambda) \text{ then } \frac{d\mathcal{L}}{dx^*} = 0
\]</span></p>
<p>And so the equation is reduced to be</p>
<p><span class="math display">\[
g(\lambda) = \mathcal{L}(x^*(\lambda), \lambda) \quad \frac{dg}{d\lambda} = \frac{d\mathcal{L}(x^*, \lambda)}{d\lambda}
\]</span></p>
<p><strong>Dual Gradient Algorithm</strong></p>
<ol type="1">
<li>Find</li>
</ol>
<p><span class="math display">\[
x^* \leftarrow \arg\min_x \mathcal{L} (x, \lambda)
\]</span></p>
<ol start="2" type="1">
<li>Compute</li>
</ol>
<p><span class="math display">\[
\frac{dg}{d\lambda} = \frac{d\mathcal{L}(x^*, \lambda)}{d\lambda}
\]</span></p>
<ol start="3" type="1">
<li>Update</li>
</ol>
<p><span class="math display">\[
\lambda \leftarrow \lambda + \alpha \frac{dg}{d\lambda}
\]</span></p>
<p><strong>Dual Gradient Descent with iLQR</strong></p>
<p>We try of optimize</p>
<p><span class="math display">\[
\min_p \sum^T_{t=1} \mathbb{E}_{p(x_t, u_t)} [c(x_t, u_t)] \text{ such that } D_{KL}(p(\tau) || \tilde{p}(\tau)) \le \epsilon
\]</span></p>
<p>The loss can be</p>
<p><span class="math display">\[
\mathcal{L} (p, \lambda) = \sum^T_{t=1} \mathbb{E}_{p(x_t, u_t)} \left[ c(x_t, u_t) - \lambda \log \tilde{p}(u_t|x_t) - \lambda \mathcal{H}(p(u_t|x_t)) \right] - \lambda \epsilon
\]</span></p>
<p>We can solve it using iLQR, actually the first step (Finding the minimum) is the hard part. But we can do it wth iLQR</p>
<p><span class="math display">\[
\min_p \sum^T_{t=1} \mathbb{E}_{p(x_t, u_t)} \left[ \frac{1}{\lambda} c(x_t, u_t) - \log \tilde{p}(u_t|x_t) - \mathcal{H}(p(u_t|x_t)) \right]
\]</span></p>
<p>Just use iLQR with the cost</p>
<p><span class="math display">\[
\tilde{c}(x_t, u_t) = \frac{1}{\lambda} c(x_t, u_t) - \log \tilde{p}(u_t|x_t)
\]</span></p>
<p><strong>Dual Gradient Descent with iLQR Algorithm</strong></p>
<ol type="1">
<li>Set the cost to be</li>
</ol>
<p><span class="math display">\[
\tilde{c}(x_t, u_t) = \frac{1}{\lambda} c(x_t, u_t) - \log \tilde{p}(u_t|x_t)
\]</span></p>
<ol start="2" type="1">
<li>Use iLQR to find using <span class="math inline">\(\tilde{c}\)</span></li>
</ol>
<p><span class="math display">\[
p^*(u_t|x_t)
\]</span></p>
<ol start="3" type="1">
<li>Then Update</li>
</ol>
<p><span class="math display">\[
\lambda \leftarrow \lambda + \alpha (D_{KL}(p(\tau) || \tilde{p}(\tau)) - \epsilon)
\]</span></p>
<p><strong>Trust Region</strong></p>
<ul>
<li><p>Bounding KL-Divergence between 2 policies controller, whether linear-gaussian or more complex is really useful</p></li>
<li><p>Bounding KL-Divergence between policies is equivalent to bounding KL-divergences between trajectory distribution</p></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<!DOCTYPE html>
<!-- KaTeX requires the use of the HTML5 doctype. Without it, KaTeX may not render properly -->
<html>
  <head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous"/>

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script src="katex.min.js"></script>
    

  </head>
  <body>

    
  </body>
</html>
</div>
<div id="refs" class="references">
<div id="ref-6301026">
<p>Durrant-Whyte, Hugh, Nicholas Roy, and Pieter Abbeel. 2012. “Learning to Control a Low-Cost Manipulator Using Data-Efficient Reinforcement Learning.” In <em>Robotics: Science and Systems Vii</em>. MITP. <a href="https://ieeexplore.ieee.org/document/6301026" class="uri">https://ieeexplore.ieee.org/document/6301026</a>.</p>
</div>
</div>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Deep%20Reinforcement%20Learning%20Lecture%208&amp;url=http%3A%2F%2Fphutoast.github.io%2Fposts%2F2019-02-12-deep-rl-lecture-8%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fphutoast.github.io%2Fposts%2F2019-02-12-deep-rl-lecture-8%2F&amp;title=Deep%20Reinforcement%20Learning%20Lecture%208">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://www.facebook.com/sharer/sharer.php?s=100&amp;p[url]=http%3A%2F%2Fphutoast.github.io%2Fposts%2F2019-02-12-deep-rl-lecture-8%2F">
        <i class="fab fa-facebook"></i>
      </a>
    </span>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Sakulwongtana (2019, Feb. 12). Phu's Website: Deep Reinforcement Learning Lecture 8. Retrieved from http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{sakulwongtana2019deep,
  author = {Sakulwongtana, Phu},
  title = {Phu's Website: Deep Reinforcement Learning Lecture 8},
  url = {http://phutoast.github.io/posts/2019-02-12-deep-rl-lecture-8/},
  year = {2019}
}</pre>
</div>
<script id="distill-bibliography" type="text/bibtex">
@INBOOK{
  6301026, 
author={Hugh Durrant-Whyte and Nicholas Roy and Pieter Abbeel}, 
booktitle={Robotics: Science and Systems VII}, 
title={Learning to Control a Low-Cost Manipulator Using Data-Efficient Reinforcement Learning}, 
year={2012}, 
volume={}, 
number={}, 
pages={}, 
keywords={}, 
doi={}, 
ISSN={}, 
publisher={MITP}, 
isbn={9780262305969}, 
url={https://ieeexplore.ieee.org/document/6301026},}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
